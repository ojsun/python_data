0. 크롤링의 모델 정석
## import 할것 (대부분)
from bs4 import BeautifulSoup           ##BeautifulSoup의 파써( html.parser )
pip install html5lib  lxml                                    +파써( html5lib/ lxml )  
import requests,                	    	## 1방법)  requests.get(url)         
from urllib.request import urlopen             2방법)  urlopen(url)    
import json 			## .json()['내용'] 파싱함
from selenium import webdriver

## select / select_all   find_all / find
   아이디 #   class .   .클래스명:first-child  .클래스명:last-child  .클래스명:nth-child(3) 
   뒤에 아무것도 없으면 모두 선택한거임   
   div 하위에서만 사용하는 .클래스명 > 요소

## 그밖에
print(html.read())  --> 가져온 html이라는 문서 읽기 프린트
print(content.text)  // .get_text / .string

##  urllib.request 사용시 프로세스
1. 웹페이지 정보 위치 확인(F12)
2. HTML 소스 불러오기              		        
	url= "https://주소"
	html =urlopen(url) 					         
3. 데이터에서 정보 가공 후 추출     		
	bs= BeautifulSoup (html, "html.parser")
	title =bs.select_one ("div > h1")
	print(html.read())        
4. 추출정보를 csv 또는 db 등에 저장,가공,시각화

## requests 사용시 프로세스
	response = requests.get(url)    # .post 있음
	html =response.content 
	bs= BeautifulSoup (html, "html.parser")
	content =bs.select_one ("div > hr")
	print(content.text)

## selenium 의 경우
from selenium import webdriver

driver= webdriver.Chrome()
driver.get('웹주소')
words=driver.find_elements(BY.CSS_SELECTOR,"...선택태그 등")
for word in words:
	print(word.text)
driver.quit

0) select ehsms find_all로 다수 추출한다면 :예)테이블 태그 크롤링
columns = []
column =table.select_one ('tr').select('td')
for col in column:
	columns.append(col.text)
print(columns)

 rows = table.select tr:not (:first child)') 첫줄 제외
1)
import requests
from urllib.request import urlopen
from bs4 import BeautifulSoup

url = 'https://ai-dev.tistory.com/1'
response = requests.get(url)
# response = urlopen(url)

soup = BeautifulSoup(response.content, 'html.parser')
title = soup.select_one('header > h1 > a')
print(title.text)
# print(title.get('href'))

2)
url = 'https://ai-dev.tistory.com/2'
response = requests.get(url)

soup = BeautifulSoup(response.content, 'html.parser')
table = soup.select_one('div.tt_article_useless_p_margin table')
rows = table.select('tr') # 'tr:not(:first-child)' - 첫번째 줄을 제외한 나머지 줄
table_list = []
for row in rows:
    row_list = []
    for td in row.select('td'):
        row_list.append(td.text)
    table_list.append(row_list)
table_list

3)
items = soup.select_one('div.tt_article_useless_p_margin > ul')
ul_list = []
for item in items.select('li'):
    ul_list.append(item.text)
print(ul_list)

4) 페이지 이동하며 크롤링
contents = []
for i in range(1, 5):
    url = f'https://ai-dev.tistory.com/{i}' 
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.content, 'html.parser')
        try:
            title = soup.select_one('div.hgroup > h1').text
            date = soup.select_one('span.date').text
            contents.append([title, date])
print(contents)

5)
