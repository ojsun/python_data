{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca3726a",
   "metadata": {},
   "source": [
    "기본 코드 프레임  //https://www.snugarchive.com/blog/python-web-scraping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aea53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "url = \"www.snugarchive.com\" \n",
    "res = requests.get(url) \n",
    "res.raise_for_status() # 정상 200\n",
    "soup = BeautifulSoup(res.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f57087",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"[WhatIsMyBrowser에 나타난 나의 유저 정보]\"}\n",
    "res = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dab7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"고양이 장난감.csv\"\n",
    "f = open(filename, \"w\", encoding=\"utf-8-sig\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "columns_title = [\"컬럼명1\", \"컬럼명2\"]\n",
    "writer.writerow(columns_title)\n",
    "\n",
    "data = [\"결과1\", \"결과2\"] # [] 리스트 자료구조\n",
    "writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제-naver 인기만화 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55eb2373",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(res\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m cartoonsBox \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mol\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masideBoxRank\u001b[39m\u001b[38;5;124m\"\u001b[39m}) \u001b[38;5;66;03m# 전체 영역에서 'a' 태그를 찾지 않고 인기 급상승 영역으로 범위 제한\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m cartoons \u001b[38;5;241m=\u001b[39m cartoonsBox\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# 인기 급상승 영역에서 'a'태그 모두 찾아 변수 cartoons에 할당\u001b[39;00m\n\u001b[0;32m     26\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 반복문으로 제목 가져오기(터미널 창 출력 및 엑셀 저장)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# 라이브러리 준비하기\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url =\"https://comic.naver.com/webtoon/weekday\"\n",
    "\n",
    "# 엑셀 파일로 저장하기\n",
    "filename = \"네이버 웹툰 인기 순위.csv\"\n",
    "f = open(filename, \"w\", encoding=\"utf-8-sig\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "\n",
    "columns_name = [\"순위\", \"웹툰명\"] # 컬럼 속성명 만들기\n",
    "\n",
    "writer.writerow(columns_name)\n",
    "\n",
    "# 웹 서버에 요청하기\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "\n",
    "# soup 객체 만들기\n",
    "soup = BeautifulSoup(res.text, \"lxml\")\n",
    "cartoonsBox = soup.find('ol', attrs={\"class\": \"asideBoxRank\"}) # 전체 영역에서 'a' 태그를 찾지 않고 인기 급상승 영역으로 범위 제한\n",
    "cartoons = cartoonsBox.find_all('a') # 인기 급상승 영역에서 'a'태그 모두 찾아 변수 cartoons에 할당\n",
    "\n",
    "i = 1\n",
    "\n",
    "# 반복문으로 제목 가져오기(터미널 창 출력 및 엑셀 저장)\n",
    "for cartoon in cartoons: \n",
    "  title = cartoon.get(\"title\") \n",
    "  print(f\"{str(i)}위: {title}\")\n",
    "  data = [str(i), title]\n",
    "  writer.writerow(data)\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 영화정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa52291",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://www.imdb.com/title/tt1475582/episodes?season=1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m url \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.imdb.com/title/tt1475582/episodes?season=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(season)\n\u001b[0;32m     15\u001b[0m res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m---> 16\u001b[0m res\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     18\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(res\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m     20\u001b[0m season \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh3\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_top\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39mget_text()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.imdb.com/title/tt1475582/episodes?season=1"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "filename = \"셜록 시즌 정보.csv\"\n",
    "f = open(filename, \"w\", encoding=\"utf-8-sig\", newline=\"\")\n",
    "writer = csv.writer(f)\n",
    "\n",
    "attributes = [\"시즌\", \"제목\", \"리뷰수\", \"평점\"]\n",
    "writer.writerow(attributes)\n",
    "\n",
    "# 시즌 1부터 시즌 4까지 url 중 숫자 부분만 바꿔서 반복문으로 가져오기\n",
    "for season in range(1, 5): \n",
    "  url =\"https://www.imdb.com/title/tt1475582/episodes?season={}\".format(season)\n",
    "  res = requests.get(url)\n",
    "  res.raise_for_status()\n",
    "\n",
    "  soup = BeautifulSoup(res.text, \"lxml\") \n",
    "\n",
    "  season = soup.find(\"h3\", {\"id\": \"episode_top\"}).get_text()[-1] \n",
    "  episodes = soup.find_all(\"div\", attrs={\"itemprop\": \"episodes\"})\n",
    "\n",
    "  for episode in episodes:\n",
    "    title = episode.find(\"a\", attrs={\"itemprop\": \"name\"}).get_text()\n",
    "    review = episode.find(\"span\", attrs={\"class\": \"ipl-rating-star__total-votes\"}).get_text()[1:-1]\n",
    "    rate = episode.find(\"span\", attrs={\"class\": \"ipl-rating-star__rating\"}).get_text()\n",
    "    \n",
    "    data_rows = [season, title, review, rate]\n",
    "    # print(season)\n",
    "    # print(f\"제목: {title}\")\n",
    "    # print(f\"리뷰수: {review}\")\n",
    "    # print(f\"평점: {rate}\")\n",
    "    # print(\"-\"*30)\n",
    "    writer.writerow(data_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
