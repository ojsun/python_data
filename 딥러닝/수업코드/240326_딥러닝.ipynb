{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86b136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeec059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# 데이터 불러오기\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# 데이터 확인하기\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(X_train[0][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e6b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272908d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_name = ['티셔츠/윗도리', '바지', '스웨터', '드레스', \n",
    "'코트', '샌들', '셔츠', '스니커즈', '가방', '앵클부츠']\n",
    "class_name[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b41d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa51a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "arr = Image.open('1.jpeg')\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4fb8f3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(arr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9998586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "red_arr = np.array(arr)[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0738a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(red_arr, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75379750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fhd > 1920*1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ebf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1920*1080 > 1280 * 720 > 640 * 320 > 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1280 * 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed673ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01162d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:2].reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971213ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca71a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X - min() / max() - min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc4f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 스케일링\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# 28 x 28 > 784 로 변환\n",
    "X_train = X_train.reshape(-1,784)\n",
    "X_test = X_test.reshape(-1,784)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09e8b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "diabetes.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc950e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ec848",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bd6ea2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bcdcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b3fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493be840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassNetwork:\n",
    "    def __init__(self, units = 10): # 전과 동일\n",
    "        self.units = units \n",
    "        self.w1 = None \n",
    "        self.b1 = None \n",
    "        self.w2 = None \n",
    "        self.b2 = None \n",
    "        self.a1 = None \n",
    "        self.losses = []\n",
    "    def forpass(self, x): \n",
    "        z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = self.sigmoid(z1) # 활성 함수 이름 변경\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        return z2\n",
    "    def backprop(self, x, err): # 전과 동일\n",
    "        m = len(x)\n",
    "        w2_grad = np.dot(self.a1.T, err) / m\n",
    "        b2_grad = np.sum(err) / m\n",
    "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
    "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
    "    def sigmoid(self, z): # 시그모이드 함수\n",
    "        z = np.clip(z, -100, None)\n",
    "        a = 1 / (1 + np.exp(-z))\n",
    "        return a\n",
    "\n",
    "    def softmax(self, z): #소프트맥스 함수\n",
    "        z = np.clip(z, -100, None)\n",
    "        exp_z = np.exp(z)\n",
    "        return exp_z / np.sum(exp_z, axis = 1).reshape(-1, 1)\n",
    "    def init_weights(self, n_features, n_classes): # 클래스 개수 받음\n",
    "        np.random.seed(0)\n",
    "        self.w1 = np.random.normal(0, 1, (n_features, self.units))\n",
    "        self.b1 = np.zeros(self.units)\n",
    "        self.w2 = np.random.normal(0, 1, (self.units, n_classes)) # 클래스 개수 포함\n",
    "        self.b2 = np.zeros(n_classes) # 클래스 개수 포함\n",
    "    def training(self, x, y, m):\n",
    "        z = self.forpass(x)\n",
    "        a = self.softmax(z) # 출력 계층 활성 함수 변경\n",
    "        err = -(y - a)\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        self.w1 -= w1_grad\n",
    "        self.b1 -= b1_grad\n",
    "        self.w2 -= w2_grad\n",
    "        self.b2 -= b2_grad\n",
    "        return a\n",
    "    def fit(self, x, y, epochs = 100):\n",
    "        m = len(x)\n",
    "        self.init_weights(x.shape[1], y.shape[1]) # 가중치 초기화시 클래스 개수 포함\n",
    "        for I in range(epochs): \n",
    "            print('.', end='') # epochs 1번마다 . 찍음\n",
    "            a = self.training(x, y, m)\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            loss = np.sum(-y * np.log(a)) # 크로스 엔트로피 손실 함수\n",
    "            self.losses.append(loss / m)\n",
    "    def predict(self, x):\n",
    "        z = self.forpass(x)\n",
    "        return np.argmax(z, axis = 1) # 예측한 결과에서 가장 큰 확률 인덱스\n",
    "    def score(self, x, y):\n",
    "        # 정답 인덱스 확인\n",
    "        return np.mean(self.predict(x) == np.argmax(y, axis = 1)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d2f442f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 - 다중분류 : y데이터를 원-핫 인코딩 해야한다.\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "print(y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169191e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass = MultiClassNetwork(units = 100)\n",
    "multiclass.fit(X_train, y_train_encoded, epochs = 100)\n",
    "multiclass.score(X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('t.png')\n",
    "arr = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125fe15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sample = arr[:,:,1].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2aee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(arr[:,:,1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046da055",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3382ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass.predict(X_test_sample.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c65e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbbf5893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 회귀, 이진분류, 다중분류\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, kind = 0, units = 10): \n",
    "        self.kind = kind\n",
    "        # kind = {0, 1, 2}\n",
    "        # 0:회귀, 1:이진, 2:다중\n",
    "        self.units = units \n",
    "        self.w1 = None \n",
    "        self.b1 = None \n",
    "        self.w2 = None \n",
    "        self.b2 = None \n",
    "        self.a1 = None \n",
    "        self.losses = []\n",
    "    # 정방향 계산\n",
    "    def forpass(self, x): \n",
    "        z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = self.sigmoid(z1) # 활성화함수(시그모이드)\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        return z2\n",
    "    # 역전파 계산\n",
    "    def backprop(self, x, err): \n",
    "        m = len(x)\n",
    "        w2_grad = np.dot(self.a1.T, err) / m\n",
    "        b2_grad = np.sum(err) / m\n",
    "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
    "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
    "    # 시그모이드 함수\n",
    "    def sigmoid(self, z): \n",
    "        z = np.clip(z, -100, None)\n",
    "        a = 1 / (1 + np.exp(-z))\n",
    "        return a\n",
    "    #소프트맥스 함수\n",
    "    def softmax(self, z): \n",
    "        z = np.clip(z, -100, None)\n",
    "        exp_z = np.exp(z)\n",
    "        return exp_z / np.sum(exp_z, axis = 1).reshape(-1, 1)\n",
    "    # 가중치 초기화\n",
    "    def init_weights(self, n_features, n_classes): \n",
    "        np.random.seed(0)\n",
    "        self.w1 = np.random.normal(0, 1, (n_features, self.units))\n",
    "        self.b1 = np.zeros(self.units)\n",
    "        self.w2 = np.random.normal(0, 1, (self.units, n_classes)) \n",
    "        self.b2 = np.zeros(n_classes) \n",
    "    # 회귀, 분류일때 달라지는 지점\n",
    "    ######################################\n",
    "    def training(self, x, y, m):\n",
    "        z = self.forpass(x)\n",
    "        # 출력층에 활성화 함수적용\n",
    "        if self.kind == 0:\n",
    "            # 회귀 : y = x\n",
    "            a = z\n",
    "        elif self.kind == 1:\n",
    "            # 이진분류 : 시그모이드\n",
    "            a = self.sigmoid(z)\n",
    "        else:\n",
    "            # 다중분류 : 소프트맥스\n",
    "            a = self.softmax(z) \n",
    "        err = -(y - a)\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        self.w1 -= w1_grad\n",
    "        self.b1 -= b1_grad\n",
    "        self.w2 -= w2_grad\n",
    "        self.b2 -= b2_grad\n",
    "        return a\n",
    "    def loss(self, a, y, m):\n",
    "        if self.kind == 2:\n",
    "            # 다중분류 : 크로스 엔트로피 손실 함수\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            loss = np.sum(-y * np.log(a)) \n",
    "        elif self.kind == 1:\n",
    "            # 이진분류 : 로지스틱 손실 함수\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            loss = np.sum(-(y * np.log(a) + (1 - y) * np.log(1 - a)))\n",
    "        else:\n",
    "            # 회귀\n",
    "            loss = np.sum((y - a) ** 2)\n",
    "        self.losses.append(loss / m)\n",
    "    ####################################################################    \n",
    "    \n",
    "    def fit(self, x, y, epochs = 100):\n",
    "        m = len(x)\n",
    "        self.init_weights(x.shape[1], y.shape[1]) # 가중치 초기화시 클래스 개수 포함\n",
    "        for I in range(epochs): \n",
    "            print('.', end='') # epochs 1번마다 . 찍음\n",
    "            a = self.training(x, y, m)\n",
    "            self.loss(a, y, m)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ca97f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(kind = 2)\n",
    "nn.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048dbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "nn = NeuralNetwork(kind = 0)\n",
    "nn.fit(X, y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263287a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(kind = 0)\n",
    "nn.fit(X, y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MultiClassNetwork:\n",
    "    def __init__(self, units=10, units2=10): # 은닉층 노드 수 두 개 입력받음\n",
    "        self.units = units \n",
    "        self.units2 = units2 # 새로운 은닉층의 노드 수\n",
    "        self.w1 = None \n",
    "        self.b1 = None \n",
    "        self.w2 = None \n",
    "        self.b2 = None \n",
    "        self.w3 = None  # 새로운 은닉층의 가중치\n",
    "        self.b3 = None  # 새로운 은닉층의 편향\n",
    "        self.a1 = None \n",
    "        self.a2 = None  # 새로운 은닉층의 출력\n",
    "        self.losses = []\n",
    "\n",
    "    def forpass(self, x): \n",
    "        z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = self.sigmoid(z1) \n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = self.sigmoid(z2)  # 새로운 은닉층의 출력\n",
    "        z3 = np.dot(self.a2, self.w3) + self.b3  # 새로운 은닉층의 출력을 다음 은닉층의 입력으로 사용\n",
    "        return z3\n",
    "\n",
    "    def backprop(self, x, err): \n",
    "        m = len(x)\n",
    "        w3_grad = np.dot(self.a2.T, err) / m  # 새로운 은닉층의 그래디언트 계산\n",
    "        b3_grad = np.sum(err) / m\n",
    "        err_to_hidden2 = np.dot(err, self.w3.T) * self.a2 * (1 - self.a2)  # 새로운 은닉층에서의 오차\n",
    "        w2_grad = np.dot(self.a1.T, err_to_hidden2) / m  # 은닉층2의 그래디언트 계산\n",
    "        b2_grad = np.sum(err_to_hidden2, axis=0) / m\n",
    "        err_to_hidden = np.dot(err_to_hidden2, self.w2.T) * self.a1 * (1 - self.a1)\n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
    "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad, w3_grad, b3_grad  # 새로운 은닉층의 그래디언트 반환\n",
    "\n",
    "    def sigmoid(self, z): \n",
    "        z = np.clip(z, -100, None)\n",
    "        a = 1 / (1 + np.exp(-z))\n",
    "        return a\n",
    "\n",
    "    def softmax(self, z): \n",
    "        z = np.clip(z, -100, None)\n",
    "        exp_z = np.exp(z)\n",
    "        return exp_z / np.sum(exp_z, axis=1).reshape(-1, 1)\n",
    "\n",
    "    def init_weights(self, n_features, n_classes): \n",
    "        np.random.seed(0)\n",
    "        self.w1 = np.random.normal(0, 1, (n_features, self.units))\n",
    "        self.b1 = np.zeros(self.units)\n",
    "        self.w2 = np.random.normal(0, 1, (self.units, self.units2))  # 은닉층 2의 가중치\n",
    "        self.b2 = np.zeros(self.units2)\n",
    "        self.w3 = np.random.normal(0, 1, (self.units2, n_classes))  # 새로운 은닉층의 가중치\n",
    "        self.b3 = np.zeros(n_classes)\n",
    "\n",
    "    def training(self, x, y, m):\n",
    "        z = self.forpass(x)\n",
    "        a = self.softmax(z) \n",
    "        err = -(y - a)\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad, w3_grad, b3_grad = self.backprop(x, err)\n",
    "        self.w1 -= w1_grad\n",
    "        self.b1 -= b1_grad\n",
    "        self.w2 -= w2_grad\n",
    "        self.b2 -= b2_grad\n",
    "        self.w3 -= w3_grad  # 새로운 은닉층의 가중치 업데이트\n",
    "        self.b3 -= b3_grad  # 새로운 은닉층의 편향 업데이트\n",
    "        return a\n",
    "\n",
    "    def fit(self, x, y, epochs=100):\n",
    "        m = len(x)\n",
    "        self.init_weights(x.shape[1], y.shape[1])\n",
    "        for i in range(epochs): \n",
    "            print('.', end='') \n",
    "            a = self.training(x, y, m)\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            loss = np.sum(-y * np.log(a)) \n",
    "            self.losses.append(loss / m)\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = self.forpass(x)\n",
    "        return np.argmax(z, axis=1)\n",
    "\n",
    "    def score(self, x, y):\n",
    "        return np.mean(self.predict(x) == np.argmax(y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51579f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass = MultiClassNetwork(units = 128, units2 = 64)\n",
    "multiclass.fit(X_train, y_train_encoded, epochs = 100)\n",
    "multiclass.score(X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63b4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(784 * 100 + 100 ) + (100 * 10 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd596dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(784 * 128 + 128 ) + (128 * 64 + 64) + (64 * 10 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(multiclass.losses)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "print(multiclass.losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31069a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(0, 2 / np.sqrt(10000), (10000)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46263286",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(0, 2 / np.sqrt(10000000), (10000000)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualLayer():\n",
    "    def __init__(self, units = 10):\n",
    "        self.units = units\n",
    "        self.w1 = None\n",
    "        self.b1 = None\n",
    "        self.w2 = None\n",
    "        self.b2 = None\n",
    "        self.a1 = None\n",
    "        self.losses = []\n",
    "    def forpass(self, x):\n",
    "        z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = self.activation(z1)\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        return z2\n",
    "    def backprop(self, x, err):\n",
    "        m = len(x)\n",
    "        w2_grad = np.dot(self.a1.T, err) / m\n",
    "        b2_grad = np.sum(err) / m\n",
    "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
    "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
    "    \n",
    "    def init_weights(self, n_features):\n",
    "        self.w1 = np.ones((n_features, self.units))\n",
    "        self.b1 = np.zeros(self.units)\n",
    "        self.w2 = np.ones((self.units, 1))\n",
    "        self.b2 = 0\n",
    "    def training(self, x, y, m):\n",
    "        z = self.forpass(x)\n",
    "        a = self.activation(z)\n",
    "        err = -(y - a)\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        self.w1 -= w1_grad\n",
    "        self.b1 -= b1_grad\n",
    "        self.w2 -= w2_grad\n",
    "        self.b2 -= b2_grad\n",
    "        return a\n",
    "    \n",
    "    def activation(self, z):\n",
    "        z = np.clip(z, -100, None)\n",
    "        a = 1 / (1 + np.exp(-z))\n",
    "        return a\n",
    "    \n",
    "    def fit(self, x, y, epochs = 100):\n",
    "        y = y.reshape(-1,1)\n",
    "        m = len(x)\n",
    "        self.init_weights(x.shape[1]) \n",
    "        for i in range(epochs):\n",
    "            a = self.training(x, y, m)\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            loss = np.sum(-(y * np.log(a) + (1 - y) * np.log(1 - a)))\n",
    "            self.losses.append(loss / m)\n",
    "    def predict(self, x):\n",
    "        z = self.forpass(x)\n",
    "        return z > 0\n",
    "    def score(self, x, y):\n",
    "        return np.mean(self.predict(x) == y.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2_regular(DualLayer): \n",
    "    def __init__(self, units = 10, l2 = 0):\n",
    "        self.units = units \n",
    "        self.w1 = None \n",
    "        self.b1 = None \n",
    "        self.w2 = None \n",
    "        self.b2 = None \n",
    "        self.a1 = None \n",
    "        self.l2 = l2\n",
    "        self.losses = []\n",
    "    def training(self, x, y, m):\n",
    "        z = self.forpass(x)\n",
    "        a = self.activation(z)\n",
    "        err = -(y - a)\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        self.w1 -= w1_grad + self.l2 * self.w1\n",
    "        self.b1 -= b1_grad\n",
    "        self.w2 -= w2_grad + self.l2 * self.w2\n",
    "        self.b2 -= b2_grad \n",
    "        return a\n",
    "    \n",
    "    def fit(self, x, y, epochs = 100):\n",
    "        y = y.reshape(-1,1)\n",
    "        m = len(x)\n",
    "        self.init_weights(x.shape[1]) \n",
    "        for i in range(epochs):\n",
    "            a = self.training(x, y, m)\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            loss = np.sum(-(y * np.log(a) + (1 - y) * np.log(1 - a))) + (self.l2 / 2) * (np.sum(self.w1 ** 2) + np.sum(self.w2 ** 2))\n",
    "            # l1일때\n",
    "#             loss = np.sum(-(y * np.log(a) + (1 - y) * np.log(1 - a))) + (self.l1) * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2)))\n",
    "            self.losses.append(loss / m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(np.array([-1,1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597aafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_1 = L2_regular(l2 = 0.001)\n",
    "l2_1.fit(X_train_scaled, y_train, epochs = 1000)\n",
    "print(l2_1.score(X_test_scaled, y_test))\n",
    "l2_2 = L2_regular(l2 = 0.01)\n",
    "l2_2.fit(X_train_scaled, y_train, epochs = 1000)\n",
    "print(l2_2.score(X_test_scaled, y_test))\n",
    "l2_3 = L2_regular(l2 = 0.1)\n",
    "l2_3.fit(X_train_scaled, y_train, epochs = 1000)\n",
    "print(l2_3.score(X_test_scaled, y_test))\n",
    "l2_4 = L2_regular(l2 = 1)\n",
    "l2_4.fit(X_train_scaled, y_train, epochs = 1000)\n",
    "print(l2_4.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l2_1.losses, 'r', label = 'L2_1')\n",
    "plt.plot(l2_2.losses, 'g', label = 'L2_2')\n",
    "plt.plot(l2_3.losses, 'b', label = 'L2_3')\n",
    "plt.plot(l2_4.losses, 'y', label = 'L2_4')\n",
    "# plt.ylim(0,0.6)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee882cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944c9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
