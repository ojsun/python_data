{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c0ae5-4d38-4379-ad6e-10c728cf0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc8267f-e48a-4480-b322-2eb4cca8cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  신경망 학습 : 벡터 연산, 행렬 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d179034-d1b3-438c-bd07-1fea3ae7396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ac61c-e42e-444b-876f-0718a56bee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80543e-4123-4d52-9d88-4e182439fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3/22 코드  : 분류\n",
    "## 단층 퍼셉트론\n",
    "class SingleLayer:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.losses = []        \n",
    "    def forpass(self, x):\n",
    "        z = np.dot(x, self.w) + self.b\n",
    "        return z\n",
    "    def backprop(self, x, err):\n",
    "        m = len(x)\n",
    "        w_grad = np.dot(x.T, err) / m\n",
    "        b_grad = np.sum(err) / m  # np.mean(err)\n",
    "        return w_grad, b_grad\n",
    "    def activation(self, z):\n",
    "        z = np.clip(z, -100, None)\n",
    "        a = 1 / (1 + np.exp(-z))\n",
    "        return a\n",
    "    def predict(self, x):     # y 결과 값\n",
    "        z = self.forpass(x)\n",
    "        return z > 0\n",
    "    def score(self, x, y):\n",
    "        return np.mean(self.predict(x) == y.reshape(-1, 1))  \n",
    "    def fit(self, x, y, epochs = 100, random_state = None):\n",
    "        y = y.reshape(-1,1) # 열 벡터로 변환\n",
    "        m = len(x)\n",
    "        self.w = np.ones((x.shape[1], 1)) # 가중치 초기화\n",
    "        self.b = 0 # 절편 초기화\n",
    "        for i in range(epochs):\n",
    "            z = self.forpass(x)\n",
    "            a = self.activation(z)\n",
    "            err = -(y - a)\n",
    "            w_grad, b_grad = self.backprop(x, err)\n",
    "            self.w -= w_grad\n",
    "            self.b -= b_grad\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            loss = np.mean(-(y*np.log(a) + (1-y)*np.log(1-a))) \n",
    "            self.losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae9f97-b38f-4904-ae80-ce0721e17b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 다층 신경망\n",
    "class DualLayer:     # 클래스 SingleLayer 상속// 은닉층 1개\n",
    "    def __init__(self, units = 8):  # 클래스 만들때 모든 은닉층, 가중치 등 정해 틀 만들고 시작\n",
    "        self.units = units # 은닉층의 뉴런 개수\n",
    "        self.w1 = None    # 입력 > 은닉 가중치\n",
    "        self.b1 = None    # 입력 > 은닉 절편\n",
    "        self.w2 = None    # 은닉 > 출력 가중치\n",
    "        self.b2 = None    # 은닉 > 출력 절편\n",
    "        self.a1 = None    # 은닉층의 활성화 출력/ 계속 해서 쓰므로 저장해서 씀\n",
    "        self.losses = []\n",
    "    def forpass(self, x):\n",
    "        z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = self.activation(z1)            # 상속 받아 활성함수는 시그모이드\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2  # np.dot 행렬\n",
    "        return z2\n",
    "    def backprop(self, x, err):\n",
    "        m = len(x)\n",
    "        # 은닉층 > 출력층 가중치, 절편 업데이트\n",
    "        w2_grad = np.dot(self.a1.T, err) / m    # 평균\n",
    "        b2_grad = np.sum(err) / m               # 평균\n",
    "        # 은닉층 오차\n",
    "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
    "        # 입력층 > 은닉층 가중치, 절편 업데이트        \n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
    "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
    "    def activation(self, z):\n",
    "        z = np.clip(z, -100, None)\n",
    "        a = 1 / (1 + np.exp(-z))\n",
    "        return a\n",
    "    def predict(self, x):     # y 결과 값\n",
    "        z = self.forpass(x)\n",
    "        return z > 0\n",
    "    def score(self, x, y):\n",
    "        return np.mean(self.predict(x) == y.reshape(-1, 1))  \n",
    "  \n",
    "    def init_weights(self, n_features):        # 가중치 초기화  \n",
    "        self.w1 = np.ones((n_features, self.units))  # 2차원으로 만들어야 행렬곱 가능\n",
    "        self.b1 = np.zeros(self.units)\n",
    "        self.w2 = np.ones((self.units, 1))\n",
    "        self.b2 = 0\n",
    "    def training(self, x, y, m): ## 마지막 활성함수므로 분류할지 회귀할지 정하고 코드수정할것          \n",
    "        z = self.forpass(x)\n",
    "        a = self.activation(z)\n",
    "        err = -(y - a)\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        self.w1 -= w1_grad \n",
    "        self.b1 -= b1_grad\n",
    "        self.w2 -= w2_grad \n",
    "        self.b2 -= b2_grad\n",
    "        return a\n",
    "    def fit(self, x, y, epochs = 100):  # \n",
    "        y = y.reshape(-1,1)\n",
    "        m = len(x)\n",
    "        self.init_weights(x.shape[1])\n",
    "        for i in range(epochs):\n",
    "            a = self.training(x, y, m)    \n",
    "            a = np.clip(a, 1e-10, 1-1e-10)   # a2값?  \n",
    "            loss = np.sum(-(y * np.log(a) + (1 - y) * np.log(1 - a)))\n",
    "            self.losses.append(loss / m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2765d0-cad8-48e2-80aa-18dca215de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_layer = DualLayer()\n",
    "dual_layer.fit(X_train_scaled, y_train, epochs=1000)\n",
    "print(dual_layer.score(X_test_scaled, y_test))\n",
    "\n",
    "plt.plot(dual_layer.losses)\n",
    "plt.ylim(0,0.6)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "print(dual_layer.losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f912c-d719-4b1d-8c8f-7c31f8f6a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 다층 신경망 - 가중치 초기화 개선 ==> 손실함수 옵티마이저\n",
    "## 초반에 점을 찍는게 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487877c0-7332-4901-8b92-68b0a1b019b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomInitNetwork(DualLayer):\n",
    "    def init_weights(self, n_features):\n",
    "        # 랜덤값 고정\n",
    "        np.random.seed(0)\n",
    "        # 평균이 0, 표준편차가 1인 수로 랜덤하게 생성   \n",
    "        self.w1 = np.random.normal(0, 1, (n_features, self.units))   \n",
    "        self.b1 = np.zeros(self.units)\n",
    "        self.w2 = np.random.normal(0, 1, (self.units, 1))\n",
    "        self.b2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df1739-400a-400a-85ea-836252ae2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_init_net = RandomInitNetwork()\n",
    "random_init_net.fit(X_train_scaled, y_train, epochs = 1000)\n",
    "plt.plot(random_init_net.losses)\n",
    "plt.ylim(0,0.6)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "print(random_init_net.losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5200ce82-d8ad-4b4c-86e0-8e434fbf676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 초기값 다른 것 테스트\n",
    "plt.plot(dual_layer.losses, 'b', label = 'Dual')\n",
    "plt.plot(random_init_net.losses, 'r', label = 'Random')\n",
    "plt.ylim(0,0.6)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# 가중치를 1로 고정하고 학습시키는 것보다 무작위로초기화하는 것이 훨씬 빠르고 매끄럽게 손실 함수 값이\n",
    "# 줄어든 것을 확인할 수 있다.  ==> 초기화흫 랜덤으로 하는 것이 중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea7207-6e8a-4550-ad39-89639eee7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 신경망 학습: 다중 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b1400-3fcb-406d-b2bb-d192a85f7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 activate 함수를 시스모이드, 소프트맥스 함수로 나누고 새로 만듦\n",
    "def sigmoid(self, z):\n",
    "    z =np.clip (z, 100, None)\n",
    "    a = 1 / (1 + np.exp(-z))\n",
    "    return a\n",
    "    \n",
    "def softmax (self,z):\n",
    "    z=np.clip(z, 100, None)\n",
    "    exp_z= np.exp (z)\n",
    "    return exp_z / np.su(exp_z , axis = 1). reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67150338-2de1-4b62-9857-f1f9f65bd0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 다중 분류 클래스 만들기  : \n",
    "# 다똑같은데, 다른 점 마지막 활성함수(소프트맥스)\n",
    "\n",
    "class MultiClassNetwork:\n",
    "    def __init__(self, units = 10): # 전과 동일\n",
    "        self.units = units \n",
    "        self.w1 = None \n",
    "        self.b1 = None \n",
    "        self.w2 = None \n",
    "        self.b2 = None \n",
    "        self.a1 = None \n",
    "        self.losses = []\n",
    "    def forpass(self, x): \n",
    "        z1 = np.dot(x, self.w1) + self.b1\n",
    "        self.a1 = self.sigmoid(z1)             # 활성 함수 이름 변경\n",
    "        z2 = np.dot(self.a1, self.w2) + self.b2 \n",
    "        return z2\n",
    "    def backprop(self, x, err): # 전과 동일\n",
    "        m = len(x)\n",
    "        w2_grad = np.dot(self.a1.T, err) / m\n",
    "        b2_grad = np.sum(err) / m\n",
    "        err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)\n",
    "        w1_grad = np.dot(x.T, err_to_hidden) / m\n",
    "        b1_grad = np.sum(err_to_hidden, axis=0) / m\n",
    "        return w1_grad, b1_grad, w2_grad, b2_grad\n",
    "    def sigmoid(self, z): # 시그모이드 함수\n",
    "        z = np.clip(z, -100, None)\n",
    "        a = 1 / (1 + np.exp(-z))\n",
    "        return a\n",
    "    def softmax(self, z):     #소프트맥스 함수\n",
    "        z = np.clip(z, -100, None)\n",
    "        exp_z = np.exp(z)\n",
    "        return exp_z / np.sum(exp_z, axis = 1).reshape(-1, 1)\n",
    "    def init_weights(self, n_features, n_classes): # 클래스 개수 받음\n",
    "        np.random.seed(0)\n",
    "        self.w1 = np.random.normal(0, 1, (n_features, self.units))\n",
    "        self.b1 = np.zeros(self.units)\n",
    "        self.w2 = np.random.normal(0, 1, (self.units, n_classes)) # 클래스 개수 포함\n",
    "        self.b2 = np.zeros(n_classes) # 클래스 개수 포함\n",
    "    def training(self, x, y, m):\n",
    "        z = self.forpass(x)\n",
    "        a = self.softmax(z) # 출력 계층 활성 함수 변경\n",
    "        err = -(y - a)      # 에러값 3개 나옴\n",
    "        w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
    "        self.w1 -= w1_grad\n",
    "        self.b1 -= b1_grad\n",
    "        self.w2 -= w2_grad\n",
    "        self.b2 -= b2_grad\n",
    "        return a\n",
    "    def fit(self, x, y, epochs = 100):\n",
    "        m = len(x)\n",
    "        self.init_weights(x.shape[1], y.shape[1]) # 가중치 초기화시 클래스 개수 포함\n",
    "        for I in range(epochs): \n",
    "            print('.', end='') # epochs 1번마다 . 찍음\n",
    "            a = self.training(x, y, m)\n",
    "            a = np.clip(a, 1e-10, 1-1e-10)\n",
    "            loss = np.sum(-y * np.log(a)) # 크로스 엔트로피 손실 함수\n",
    "            self.losses.append(loss / m)\n",
    "    def predict(self, x):\n",
    "        z = self.forpass(x)\n",
    "        return np.argmax(z, axis = 1) # 예측한 결과에서 가장 큰 확률 인덱스\n",
    "    def score(self, x, y):\n",
    "        # 정답 인덱스 확인\n",
    "        return np.mean(self.predict(x) == np.argmax(y, axis = 1)) \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29320c2e-0c9d-4660-ab9b-c6364843de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris= load_iris()\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b4b6d-7c7b-42d4-9255-42b4c7922a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oh_enc=OneHotEncoder()\n",
    "y_enc=oh_enc.fit_transform(y.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f088182-1cc6-4ef9-9912-6b3466919668",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b293cd-f562-40dc-9828-178cdd562681",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi= MultiClassNetwork(units=100)\n",
    "multi.fit(X_train,y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32adbe3e-52f1-4798-a45e-7feb63568458",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(multi.losses)\n",
    "#plt.ylim(-30,30)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "print(multi.losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca737d-a26e-4a82-ba53-cfb7604d6ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736bf25-5301-47eb-acee-6efca2274d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 데이터로 실습 (내일 합시당)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# 데이터 불러오기\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# 데이터 확인하기\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(X_train[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997daacb-65e3-4bbb-bfff-474f614b748e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e64cba-725b-41ba-8f78-69c7577dbada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae125905-11ca-4b4d-b8f6-c7aaae16fd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59907992-3f5d-4c3f-ac90-abbfafa26919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cd97e-a1ef-4982-80f6-92476f895eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb65dbff-97db-4128-b806-f1ac8bcfd4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ddb1d-8682-4361-814b-bd95335ed0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce306579-e9ed-4c61-9c32-ee25513724c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1a384-81f0-4100-889f-7474a89637c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366eabd-10d0-471c-8811-d745bf541c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e1123-d47d-49ca-a852-e976e8333f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb444202-bf51-409a-9ce8-8e1bf6f573e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af689f8b-4eb7-4620-a59a-cf1deb7026e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
