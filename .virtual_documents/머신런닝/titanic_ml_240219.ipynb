import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


titanic = pd.read_csv('data/titanic.csv')
titanic.info()





# 전처리: 1) null 값 채우기
titanic['Age'].fillna(titanic['Age'].mean(),inplace=True)
titanic['Cabin'].fillna('N', inplace=True)
titanic['Embarked'].fillna('N', inplace=True)
print(titanic.isna().sum().sum())


titanic.head(5)


# 2) collumns 삭제
titanic_df=titanic.drop(['Name','PassengerId','Ticket'], axis=1)
titanic_df.head()


# 3) Cabin앞문자만 따오기
titanic_df['Cabin']=titanic_df['Cabin'].str[:1]


titanic_df.head()


# 4) 범주형 문자 --> 수치형으로 바꿈
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

lbe=LabelEncoder()
titanic_df['Sex']=lbe.fit_transform(titanic_df['Sex'])


oh=OneHotEncoder(sparse_output=False)
C_B=oh.fit_transform(titanic_df[['Cabin','Embarked']])


columns=np.hstack(['Cab_' + oh.categories_[0], 'Emb_'+ oh.categories_[1]])


titanic_df=pd.concat([titanic_df, pd.DataFrame(C_B, columns=columns)], axis=1)


titanic_df=titanic_df.drop(['Cabin','Embarked'], axis=1)


# 5) 종속변수와 독립변수 나누기
X_titanic=titanic_df.drop(['Survived'], axis=1)
y_titanic=titanic_df['Survived']

print(X_titanic.shape, y_titanic.shape)





from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test= train_test_split(X_titanic, y_titanic, test_size=0.2, random_state=0)
print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)





from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

dt_clf=DecisionTreeClassifier(random_state=0)
dt_clf.fit(X_train, y_train)
pred=dt_clf.predict(X_test)
print(f'예측정확도: {accuracy_score(y_test,pred):.3f}')





from sklearn.model_selection import cross_val_score

scores=cross_val_score(dt_clf, X_titanic, y_titanic, cv=5)
for iter_count, accuracy in enumerate(scores):
    print(f'교차검증: {iter_count}, 정확도: {accuracy:.3f}')
print(f'평균 정확도: {np.mean(scores):.3f}')


from sklearn.model_selection import KFold

kfold = KFold(n_splits=7)
dt_clf = DecisionTreeClassifier(random_state=11)
acc = []
for train_index, test_index in kfold.split(X_titanic):
    X_train, X_test = X_titanic.iloc[train_index], X_titanic.iloc[test_index]
    y_train, y_test = y_titanic.iloc[train_index], y_titanic.iloc[test_index]   
    dt_clf.fit(X_train, y_train)
    pred = dt_clf.predict(X_test)   
    acc.append(round(accuracy_score(y_test, pred), 4))
print(acc)
print(np.mean(acc))





# StandardScale 표준화
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
result = scaler.fit_transform(titanic_df[['Age', 'SibSp', 'Parch', 'Fare']])
titanic_df[['Age', 'SibSp', 'Parch', 'Fare']] = result
titanic_df.head(3)





y = titanic_df['Survived']
X = titanic_df.iloc[:, 1:]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=11)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)


from sklearn.tree import DecisionTreeClassifier
dt_clf = DecisionTreeClassifier(random_state=0)
dt_clf.fit(X_train, y_train)
pred = dt_clf.predict(X_test)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, pred))


# 한번 오차랭렬 해봄

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, pred)



