from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
user_based = np.array([[5,1,4,4],
                       [1,1,4,4],
                       [4,2,4,4],
                       [1,4,4,2]])
result = cosine_similarity(user_based)
result


import pandas as pd

pd.DataFrame(result, columns = ['김', '이', '박', '최'], index = ['김', '이', '박', '최'])


from sklearn.neighbors import NearestNeighbors
k = 2
knn = NearestNeighbors(n_neighbors= k)
knn.fit(user_based)
top_k_distances, top_k_users = knn.kneighbors(user_based)
print(top_k_distances)
print(top_k_users)



user_based = np.array([[5,1,4,4, 0],
                       [1,1,4,4, 3],
                       [4,2,4,4, 4],
                       [1,4,4,2, 1]])
result = cosine_similarity(user_based)
result


# 유사도를 기반으로 김씨가 아직 측정하지 않은 점수를 예측

# 유사한사람(박씨)의 E제품의 점수 : R
# 김씨 박씨랑의 유사도 값 : S
# E제품의 평균 평점 : M
# 김씨의 다른 제품의 평균 평점 : M2

# (R  +  ((M - M2)* S)) / S
(4 + (((8/3) - 3.5) * (1 / 4.24264069))) 





import pandas as pd
import numpy as np
import warnings; warnings.filterwarnings('ignore')
movies =pd.read_csv('data/ml/tmdb_5000_movies.csv')
print(movies.shape)
movies.head(2)



movies_df = movies[['id','title', 'genres', 'vote_average', 
'vote_count', 'popularity', 'keywords', 'overview']]
movies_df.head()



genres = movies_df['genres'].iloc[0]


genres


eval(genres)


from ast import literal_eval

literal_eval(genres)


print(eval('1 + 1'))


literal_eval('[1,2,3]')


movies_df['genres'].apply(literal_eval)


from ast import literal_eval
movies_df['genres'] = movies_df['genres'].apply(literal_eval)
movies_df['keywords'] = movies_df['keywords'].apply(literal_eval)


movies_df['genres'] = movies_df['genres'].apply(lambda x : [ y['name'] for y in x])
movies_df['keywords'] = movies_df['keywords'].apply(lambda x : [ y['name'] for y in x])
movies_df[['genres', 'keywords']].head()


from sklearn.feature_extraction.text import CountVectorizer

movies_df['genres_literal'] = movies_df['genres'].apply(lambda x : (' ').join(x))
count_vect = CountVectorizer(ngram_range=(1,2))
genre_mat = count_vect.fit_transform(movies_df['genres_literal'])
print(genre_mat.shape)


movies_df.head(1)


test_df = movies_df[['vote_average','vote_count','popularity']]
test_df.head(1)


genres_df = pd.DataFrame(genre_mat.toarray(), columns = count_vect.get_feature_names_out())


pd.concat([test_df, genres_df], axis = 1)


movies_df['keywords_literal'] = movies_df['keywords'].apply(lambda x : (' ').join(x))
count_vect = CountVectorizer(ngram_range=(1,2))
keywords_mat = count_vect.fit_transform(movies_df['keywords_literal'])
print(keywords_mat.shape)


count_vect.get_feature_names_out()


from sklearn.metrics.pairwise import cosine_similarity
genre_sim = cosine_similarity(genre_mat, genre_mat)

print(genre_sim.shape)
print(genre_sim)


genre_sim_sorted_ind = genre_sim.argsort()[:, ::-1]
print(genre_sim_sorted_ind)



def find_sim_movie(df, sorted_ind, title_name, top_n=10):
    title_movie = df[df['title'] == title_name]
    title_index = title_movie.index.values
    similar_indexes = sorted_ind[title_index, :(top_n)]
    similar_indexes = similar_indexes.reshape(-1)
    return df.iloc[similar_indexes]



similar_movies = find_sim_movie(movies_df, genre_sim_sorted_ind, 'The Godfather',10)
similar_movies



movies_df[['title','vote_average','vote_count']].sort_values('vote_average', ascending=False)[:10]



C = movies_df['vote_average'].mean()
m = movies_df['vote_count'].quantile(0.5)
print('C:',round(C,3), ', m:',round(m,3))


percentile = 0.6
m = movies_df['vote_count'].quantile(percentile)
C = movies_df['vote_average'].mean()
def weighted_vote_average(record):
    v = record['vote_count']
    R = record['vote_average']
    return ( (v/(v+m)) * R ) + ( (m/(m+v)) * C ) 

movies_df['weighted_vote'] = movies_df.apply(weighted_vote_average, axis=1)


movies_df[['title','vote_average','weighted_vote']].sort_values('weighted_vote', ascending = False)[:10]


movies_df[['title','vote_average','weighted_vote']].sort_values('vote_average', ascending=False)[:10]



import pandas as pd
import numpy as np
movies = pd.read_csv('data/ml/movies.csv')
ratings = pd.read_csv('data/ml/ratings.csv')
print(movies.shape)
print(ratings.shape)


movies


ratings


ratings = ratings[['userId', 'movieId', 'rating']]
ratings_matrix = ratings.pivot_table(values = 'rating', 
                                     index='userId', 
                                     columns='movieId')
ratings_matrix.head()



rating_movies = ratings.merge(movies, on='movieId')


ratings_matrix = rating_movies.pivot_table('rating', index='userId', columns='title')
ratings_matrix = ratings_matrix.fillna(0)
ratings_matrix.head(3)



ratings_matrix.shape


ratings_matrix_T = ratings_matrix.transpose()
item_sim = cosine_similarity(ratings_matrix_T)
item_sim_df = pd.DataFrame(data=item_sim, 
                            index=ratings_matrix.columns,
                            columns=ratings_matrix.columns)



print(item_sim_df.shape)
item_sim_df.head()


item_sim_df["Godfather, The (1972)"].sort_values(ascending=False)[:6]


# 개인 예측 평점 함수
def predict_rating(ratings_arr, item_sim_arr ):
    ratings_pred = ratings_arr.dot(item_sim_arr)/ np.array([np.abs(item_sim_arr).sum(axis=1)])
    return ratings_pred

ratings_pred = predict_rating(ratings_matrix.values , item_sim_df.values)



ratings_pred_matrix = pd.DataFrame(data=ratings_pred, 
                                    index= ratings_matrix.index,
                                    columns = ratings_matrix.columns)
ratings_pred_matrix.head(3)


actual =ratings_matrix.values[ratings_matrix.values.nonzero()].flatten()


pred = ratings_pred[ratings_matrix.values.nonzero()].flatten()


from sklearn.metrics import mean_squared_error

mean_squared_error(actual, pred)


from sklearn.metrics import mean_squared_error
def get_rmse(pred, actual):
    pred = pred[actual.nonzero()].flatten()
    actual = actual[actual.nonzero()].flatten()
    return np.sqrt(mean_squared_error(pred, actual))

print('아이템 기반 모든 인접 이웃 RMSE: ', get_rmse(ratings_pred, ratings_matrix.values ))



def predict_rating_topsim(ratings_arr, item_sim_arr, n=20):
    # 유저-아이템 행렬만큼 0행렬 생성
    pred = np.zeros(ratings_arr.shape)
    # 아이템 개수 만큼 수행
    for col in range(ratings_arr.shape[1]):
        top_n_items = [np.argsort(item_sim_arr[:, col])[:-n-1:-1]]
        # 모든 유저에 대한
        for row in range(ratings_arr.shape[0]):
            pred[row, col] = item_sim_arr[col, :][top_n_items].dot(ratings_arr[row, :][top_n_items].T) 
            pred[row, col] /= np.sum(np.abs(item_sim_arr[col, :][top_n_items])) 
    return pred



ratings_pred = predict_rating_topsim(ratings_matrix.values , item_sim_df.values, n=20)


ratings_pred


print('아이템 기반 인접 TOP-20 이웃 RMSE: ', get_rmse(ratings_pred, ratings_matrix.values ))


ratings_matrix.iloc[2].sort_values(ascending=False).head(40)


ratings_pred_matrix = pd.DataFrame(data=ratings_pred, 
index= ratings_matrix.index,
columns = ratings_matrix.columns)
ratings_pred_matrix


user_rating_id = ratings_matrix.loc[9, :]
user_rating_id[ user_rating_id > 0].sort_values(ascending=False)[:10]


def get_unseen_movies(ratings_matrix, userId):
    user_rating = ratings_matrix.loc[userId,:]
    already_seen = user_rating[ user_rating > 0].index.tolist()
    movies_list = ratings_matrix.columns.tolist()
    unseen_list = [ movie for movie in movies_list if movie not in already_seen]
    return unseen_list



def recomm_movie_by_userid(pred_df, userId, unseen_list, top_n=10):
    recomm_movies = pred_df.loc[userId, unseen_list].sort_values(ascending=False)[:top_n]
    return recomm_movies


unseen_list = get_unseen_movies(ratings_matrix, 9)
recomm_movies = recomm_movie_by_userid(ratings_pred_matrix, 9, 
                                        unseen_list, top_n=10)
recomm_movies = pd.DataFrame(data=recomm_movies.values,
                            index=recomm_movies.index,
                            columns=['pred_score'])
recomm_movies



ratings_matrix['Godfather: Part II, The (1974)']


def get_rmse(R, P, Q, non_zeros):
    error = 0
    # 두개의 분해된 행렬 P와 Q.T의 내적 곱으로 예측 R 행렬 생성
    full_pred_matrix = np.dot(P, Q.T)
    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출
    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]
    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]
    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]
    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]
    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)
    rmse = np.sqrt(mse)
    return rmse



def matrix_factorization(R, K, steps=100, learning_rate=0.01, r_lambda = 0.01):
    # 만약 데이터프레임이 들어오면
    if type(R) == 'pandas.core.frame.DataFrame':
        R = R.values

    num_users, num_items = R.shape
    # P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 랜덤한 값으로 입력합니다. 
    np.random.seed(1)
    P = np.random.normal(scale=1./ K, size=(num_users, K))
    Q = np.random.normal(scale=1./ K, size=(num_items, K))
    break_count = 0
    # R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트 객체에 저장. 
    non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]
    # 이전 코드에 이어서 작성
    # SGD기법으로 P와 Q 매트릭스를 계속 업데이트. 
    for step in range(steps):
        for i, j, r in non_zeros:
            # 실제 값과 예측 값의 차이인 오류 값 구함
            eij = r - np.dot(P[i, :], Q[j, :].T)
            # Regularization을 반영한 SGD 업데이트 공식 적용
            P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])
            Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])
        
        
        if (step % 10) == 0 :
            rmse = get_rmse(R, P, Q, non_zeros)
            print("### iteration step : ", step," rmse : ", rmse)
    return P, Q



P, Q = matrix_factorization(ratings_matrix.values, K=50, steps=100, 
                            learning_rate=0.01, r_lambda = 0.01)
pred_matrix = np.dot(P, Q.T)



ratings_pred_matrix = pd.DataFrame(data=pred_matrix, index= ratings_matrix.index,
columns = ratings_matrix.columns)
ratings_pred_matrix.head(3)



# 사용자가 관람하지 않는 영화명 추출
unseen_list = get_unseen_movies(ratings_matrix, 9)
# 아이템 기반의 인접 이웃 협업 필터링으로 영화 추천
recomm_movies = recomm_movie_by_userid(ratings_pred_matrix, 9, 
unseen_list, top_n=10)
# 평점 데이타를 DataFrame으로 생성. 
recomm_movies = pd.DataFrame(data=recomm_movies.values,
index=recomm_movies.index, columns=['pred_score'])
recomm_movies



joke = pd.read_csv('data/ml/JokeText.csv')
joke


# 컨텐츠 기반 추천 시스템
# 스탑워드 제거
from nltk.corpus import stopwords

stop_words = stopwords.words('english')


from sklearn.feature_extraction.text import CountVectorizer

cnt_vect = CountVectorizer(stop_words=stop_words, ngram_range=(1,2))


data = cnt_vect.fit_transform(joke['JokeText'])


from sklearn.metrics.pairwise import cosine_similarity

data_similarity = cosine_similarity(data)
data_sim_sorted_index = np.argsort(data_similarity, axis = 1)[:, ::-1]


print(joke['JokeText'].iloc[4])

sim_top1 = data_sim_sorted_index[4, 1]
print(joke['JokeText'].iloc[sim_top1], data_similarity[4, 1])


df = pd.read_csv('data/ml/UserRatings1.csv')
df2 = pd.read_csv('data/ml/UserRatings2.csv')


ratings = pd.concat([df, df2], axis = 1)


ratings.drop('JokeId', axis = 1, inplace=True)


ratings.head(1)


ratings = ratings.fillna(0)


item_sim = cosine_similarity(ratings)


item_sim


predict_rating(ratings.T.values, item_sim)


def predict_rating_topsim(ratings_arr, item_sim_arr, n=20):
    # 유저-아이템 행렬만큼 0행렬 생성
    pred = np.zeros(ratings_arr.shape)
    # 아이템 개수 만큼 수행
    for col in range(ratings_arr.shape[1]):
        top_n_items = [np.argsort(item_sim_arr[:, col])[:-n-1:-1]]
        # 모든 유저에 대한
        for row in range(ratings_arr.shape[0]):
            pred[row, col] = item_sim_arr[col, :][top_n_items].dot(ratings_arr[row, :][top_n_items].T) 
            pred[row, col] /= np.sum(np.abs(item_sim_arr[col, :][top_n_items])) 
    return pred

ratings_pred = predict_rating_topsim(ratings.T.values, item_sim, n=10)


ratings.T


ratings.T.values.shape


P, Q = matrix_factorization(ratings.T.values[:1000], K=50, steps=100, 
                            learning_rate=0.01, r_lambda = 0.01)
pred_matrix = np.dot(P, Q.T)


def re_matrix_factorization(R, K, P, Q, steps=100, learning_rate=0.01, r_lambda = 0.01):
    # 만약 데이터프레임이 들어오면
    if type(R) == 'pandas.core.frame.DataFrame':
        R = R.values

    num_users, num_items = R.shape
    # P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 랜덤한 값으로 입력합니다. 
    np.random.seed(1)
    
    break_count = 0
    # R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트 객체에 저장. 
    non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]
    # 이전 코드에 이어서 작성
    # SGD기법으로 P와 Q 매트릭스를 계속 업데이트. 
    for step in range(steps):
        for i, j, r in non_zeros:
            # 실제 값과 예측 값의 차이인 오류 값 구함
            eij = r - np.dot(P[i, :], Q[j, :].T)
            # Regularization을 반영한 SGD 업데이트 공식 적용
            P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])
            Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])
        
        
        if (step % 10) == 0 :
            rmse = get_rmse(R, P, Q, non_zeros)
            print("### iteration step : ", step," rmse : ", rmse)
    return P, Q



P, Q = re_matrix_factorization(ratings.T.values[:1000], K=50, P = P, Q =  Q,
                               steps=100, learning_rate=0.01, r_lambda = 0.01)
pred_matrix = np.dot(P, Q.T)


ratings_pred_matrix = pd.DataFrame(data=pred_matrix, index= ratings.T.iloc[:1000].index)
ratings_pred_matrix.head(5)


ratings.T.head(5)





# 사용자가 관람하지 않는 영화명 추출
unseen_list = get_unseen_movies(ratings.T.iloc[:1000], 'User1')
# 아이템 기반의 인접 이웃 협업 필터링으로 영화 추천
recomm_movies = recomm_movie_by_userid(ratings_pred_matrix, 'User1', 
                                        unseen_list, top_n=10)
# 평점 데이타를 DataFrame으로 생성. 
recomm_movies = pd.DataFrame(data=recomm_movies.values,
index=recomm_movies.index, columns=['pred_score'])
recomm_movies




