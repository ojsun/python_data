{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7ef099-e025-4c3f-98af-5cbfe8323c5c",
   "metadata": {},
   "source": [
    "### <사이킷런 scikit-learn>  -기본/지도학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cc135c-a434-40f3-a5a5-2a03e69e9dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "# 기본(불러오기,선택,검증 등)\n",
    "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures, Binarizer\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# 지도학습-분류\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "# 지도학습-회귀\n",
    "from sklearn.linear_model import LinearRegression,Ridge, Lasso, ElasticNet,SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# 비지도 학습\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import estimate_bandwidth\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f47138-16e3-44e5-8171-a2c36156bb63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 기타\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce9783-7d51-4beb-9572-8674d4ff01f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee715b65-ac5a-4f85-999a-9a2288cfaa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분석\n",
    "import nltk\n",
    "import re\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Okt, Hannanum, Kkma, Komoran\n",
    "from nltk.stem import LancasterStemmer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79999116-09c4-4201-8fe7-34f1aaf6d5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0. 사이킷런 파일 가져오기\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# 1. 데이터셋트 분리: train, test 로 자르기\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "X_train, X_test, y_train, y_test =train_test_split(\n",
    "    iris_data, iris_label,test_size = 0.2,random_state = 11)\n",
    "# 2. df를 자르기: 종속 / 독립 변수로 나눠서 train_test_split한다.\n",
    "y_df = df['target']\n",
    "x_df = df.drop('target', axis = 1)\n",
    "X_train, X_test, y_train, y_test = \n",
    "   train_test_split(x_df, y_df, test_size = 0.2, random_state=0)\n",
    "# 3. 모델학습\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(random_state = 0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "# 4. 예측수행- test용으로\n",
    "pred = dt_clf.predict(X_test)\n",
    "# 5. 평가 \n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd291fb-adc8-4f12-919f-98ddf66acfe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 교차검증_파라미터 성능향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a536beb3-5d13-4bb7-a425-dd0009220670",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 교차검증\n",
    "# 1) K_Fold 교차검증\n",
    "이상치 제거 등으로 중간에 빈 index가 있으면 에러남\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)\n",
    "accuracy = []\n",
    "for train_index, test_index in kfold.split(X_train):\n",
    "    X_tr = X_train[train_index]\n",
    "    X_te = X_train[test_index]\n",
    "    y_tr = y_train[train_index]\n",
    "    y_te = y_train[test_index]\n",
    "    # 데이터학습 일반화 검증\n",
    "    dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "    dt_clf.fit(X_tr, y_tr)\n",
    "    pred = dt_clf.predict(X_te)\n",
    "    acc = accuracy_score(y_te, pred)\n",
    "    accuracy.append(acc)\n",
    "print(accuracy)\n",
    "\n",
    "# 2) StratifiedKFold 교차검증\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stk = StratifiedKFold(n_splits=5)\n",
    "accuracy = []\n",
    "for train_index, test_index in stk.split(data, label):\n",
    "    X_tr = data[train_index]\n",
    "    X_te = data[test_index]\n",
    "    y_tr = label[train_index]\n",
    "    y_te = label[test_index]\n",
    "    dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "    dt_clf.fit(X_tr, y_tr)\n",
    "    pred = dt_clf.predict(X_te)\n",
    "    acc = accuracy_score(y_te, pred)\n",
    "    accuracy.append(acc)\n",
    "print(accuracy)\n",
    "\n",
    "# 3) cross_val_score 교차검증\n",
    "from sklearn.model_selection import cross_val_score, cross_validate,cross_val_predict\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state= 156)\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv = 5)\n",
    "print('교차 검증별 정확도: ', np.round(scores, 4))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))\n",
    "\n",
    "# cross_validate 교차검증 : 평가방법 2개 이상 가능\n",
    "cross_validate(dt_clf, data, label, scoring = ['accuracy', 'roc_auc_ovo'], cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328bfe9-5e9f-40ca-8376-fb673aee1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터의 성능향상: GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'max_depth' : [None, 6, 8 ,10, 12, 16 ,20, 24], 'min_samples_leaf' : range(1, 11),\n",
    "          'min_samples_split' : range(2, 11, 2)}\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print(f'GridSearchCV 최고 정확도 수치:{grid_cv.best_score_:.4f}')\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_cv.best_params_)\n",
    "\n",
    "model = grid_cv.best_estimator_\n",
    "pred = model.predict(X_test)           # 최적 파라미터로 예측하기\n",
    "pred_proba = model.predict_proba(X_test)[:,1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, pred_proba)\n",
    "print(f'accuracy: {acc:.3f}, roc_auc:{auc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735dfbae-2bcd-4cae-9c19-a1de66eae0d3",
   "metadata": {},
   "source": [
    "#### 전처리_인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ef123d-b284-42c4-a994-7fcfb3d7864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  인코딩 : 범주형 문자 --> 수치형으로 바꿈\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# 1) LabelEncoder: 종속변수 또는 독립변수 범주 2개 \n",
    "lbe=LabelEncoder()\n",
    "titanic_df['Sex']=lbe.fit_transform(titanic_df['Sex'])\n",
    "# df 전체로도 가능\n",
    "lb_enc.fit(y)                   # fit은 y의 범주 종류를 저장하는 역할\n",
    "label_iris=lb_enc.transform(y)  # 위에서 저장한 범주를 맞는 숫자로 변환\n",
    "\n",
    "# 2) OneHotEncoder: 3개 이상 독립변수 : 2차원으로 변경해야/희소행렬\n",
    "# 방안1)\n",
    "oh=OneHotEncoder(sparse_output=False)\n",
    "C_B=oh.fit_transform(titanic_df[['Cabin','Embarked']])\n",
    "columns=np.hstack(['Cab_' + oh.categories_[0], 'Emb_'+ oh.categories_[1]])\n",
    "titanic_df=pd.concat([titanic_df, pd.DataFrame(C_B, columns=columns)], axis=1)\n",
    "# 방안2)\n",
    "items = np.array(items).reshape(-1, 1)\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(items)\n",
    "oh_labels = oh_encoder.transform(items)  \n",
    "\n",
    "# 3) get_dummies - pandas 범주형 변수에서 더미변수를 자동으로 만들어주는 함수\n",
    "pd.get_dummies(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f48e3c-64b6-4516-b7e3-2a9ef45d9d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리- 표준화 / 수의 값이 끝이 없고, 기본 평균이 정해져있을때\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "cancer = load_breast_cancer()\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cancer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f74695-b2da-4312-90dc-01e796019ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 -정규화/ 수의 값이 끝이 있을때 :표준화와 모두 같음\n",
    "# ** 무조건 0-1 사이 값임\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "iris_scaled=scaler.fit_transform(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488251f-8d12-485e-be98-72fd1b580776",
   "metadata": {},
   "source": [
    "### 분류_Tree기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab00aed-9d12-4113-af3e-8b43dfc86ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 결정트리 DecisionTreeClassifier:\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_data = wine.data\n",
    "y_data = wine.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state= 156)\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "dt_clf.fit(X_train , y_train)\n",
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53867f72-5a96-461f-aeb4-e42bde950222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-1. GridSearchCV 하이퍼 파라미터 찾기\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'criterion':['gini', 'entropy'],'max_depth':[None, 2, 3, 5, 7], \n",
    "                'min_samples_split':[2,3,5,7],'min_samples_leaf':[1,3,5,7]}\n",
    "grid_dt = GridSearchCV(dt_clf, param_grid=parameters, cv=5)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "scores_df = pd.DataFrame(grid_dt.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score']]\n",
    "model = grid_dt.best_estimator_\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)\n",
    "print('GridSearchCV 최적 파라미터 :', grid_dt.best_params_)\n",
    "print(f'GridSearchCV 최고 정확도 : {grid_dt.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b69825-1d7f-44a5-b192-d19d944cbc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-2 피처 중요도 그래프 .feature_importances_\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "ftr_importances_values = model.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=wine.feature_names)\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b866d-943b-4746-9c4f-131b2c191fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-3 트리 구조 그래프\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(10,7), dpi=1200)\n",
    "plot_tree(model, filled=True, feature_names=wine.feature_names, \n",
    "    class_names=list(wine.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083891e9-a119-4fb0-825c-b78af6642749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과적합 확인하는 방법\n",
    "# cross_val_score: 학습데이터 평가점수 vs 테스트데이터 평가점수 --> 비슷해야함\n",
    "# max_dept 적은 수/ min_samples_split: split 하는 최소 샘플 수/min_samples_leaf: 리프노드에 있을 최소 샘플갯수\n",
    "    \n",
    "from sklearn.model_selection import cross_val_score\n",
    "dt_clf=DecisionTreeClassifier(random_state=0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "scores=cross_val_score(dt_clf, X_train, y_train, scoring='accuracy', cv=5)\n",
    "print('교차검증 평균 평가',scores.mean())\n",
    "print('테스트데이터 평가점수',accuracy_score(y_test, dt_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71726c-3c16-46ce-be91-2db451bc3457",
   "metadata": {},
   "source": [
    "#### ensemble 학습\n",
    "1) 보팅 Voting  \n",
    "        :한 데이터셋 + 분류기 다수:여러가지 알고리즘 사용, 다수결 원칙으로 투표로 결과 예측\n",
    "2) 배깅 Bagging  \n",
    "        : 하나의 알고리즘을 다양한 데이터로 학습하여 예측결과를 통합/ RandomForest\n",
    "3) 부스팅 Boosting : 순차적으로 학습-예측하면서 오류개선하며 가중치 조정.딥러닝 학습방식 \n",
    "        부스팅: 하나의 알고리즘 여러번 순차적으로 학습시켜서 가중치를 업데이트하는 방법\n",
    "     : GBM, AdaBoost, XGBoost, LightGBM(속도 좋고, 과적합 문제 약간), \n",
    "        CatBoost(속도 좋고, 과적합 개선)\n",
    "4) 스태킹 Stacking : 성능이 비슷한 약한 여러 모델로 작업하여 예측한 값을 최종 모델을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11896ad6-f8b9-43e7-bf93-c2faf8789024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) ensemble 학습: Voting\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "knn_clf= KNeighborsClassifier()\n",
    "vo_clf = VotingClassifier( estimators=[('LR',lr_clf), ('DT',dt_clf),('KNN', knn_clf)] , voting='soft' )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2 , random_state= 0)\n",
    "vo_clf.fit(X_train , y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print(f'Voting 분류기 정확도: {accuracy_score(y_test,pred):.4f}')\n",
    "\n",
    "classifiers = [lr_clf, dt_clf, knn_clf]\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train , y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    class_name= clf.__class__.__name__\n",
    "    print(f'{class_name} 정확도: {accuracy_score(y_test, pred):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd805c-5d86-45e6-b335-cefca8039457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) ensemble 학습: RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2 , random_state= 0)\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "print(f'랜덤 포레스트 정확도: {accuracy:.4f}')\n",
    "\n",
    "# 랜덤포레스트 파이퍼 파라미터 튜닝 GridSearchCV\n",
    "params = {'n_estimators':[100], 'max_depth' : [6, 8, 10, 12], \n",
    "          'min_samples_leaf' : [8, 12, 18 ],'min_samples_split' : [8, 16, 20]}\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=3, n_jobs=-1, verbose=True)\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('GridSearchCV 최적 파라미터:', grid_cv.best_params_)\n",
    "print(f'GridSearchCV 최고 정확도: {grid_cv.best_score_:.4f}')\n",
    "model = grid_cv.best_estimator_\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)\n",
    "\n",
    "# 피쳐 중요도 그래프\n",
    "ftr_importances_values = rf_clf.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values, index=cancer.feature_names )\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de938b73-c3fb-4c99-9c91-d758b424f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) ensemble 학습: GBM/ GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2 , random_state= 0)\n",
    "gb_clf = GradientBoostingClassifier( n_estimators=200,learning_rate=0.05,, random_state=0,verbose=True )\n",
    "gb_clf.fit(X_train , y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print(f'GBM 정확도: {gb_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d4a75-7b0a-4d9c-abc1-1fe9c3b08734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) ensemble 학습: 사이킷런 XGBClassifier \n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "dataset = load_breast_cancer()\n",
    "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "cancer_df['target'] = dataset.target\n",
    "X_features = cancer_df.iloc[:, :-1]\n",
    "y_label = cancer_df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label,test_size=0.2, random_state=156 )\n",
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train,test_size=0.1, random_state=156 )\n",
    "xgb_wrapper = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "evals = [(X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, eval_metric = \"logloss\",early_stopping_rounds=10,eval_set=evals)\n",
    "preds = xgb_wrapper.predict(X_test)\n",
    "pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "accuracy_score(y_test, pred)\n",
    "\n",
    "# xgb_wrapper.feature_importances_ 로 그래프\n",
    "ftr_importances_values = xgb_wrapper.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values, index=cancer.feature_names )\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d24ea9-f8e2-4e1d-b17e-56216a7ab01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 스태킹 앙상블\n",
    "# 4개의 모델(KNN, RF, Ada, DT)를 통해 개별 예측/최종 Logistic 모델을 사용하여 예측 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39baa9da-68b3-4b83-a3eb-9aafc89c6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stack = StackingClassifier([('Gaus', GaussianNB()),\n",
    "                            ('DT', DecisionTreeClassifier(random_state=0)),\n",
    "                            ('Knn', KNeighborsClassifier())],\n",
    "                           final_estimator=LogisticRegression(random_state=0),stack_method='predict')\n",
    "stack.fit(X_train, y_train)\n",
    "pred = stack.predict(X_test)\n",
    "pred_proba = stack.predict_proba(X_test)\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b8663-aa9e-4525-be00-2a3ef6ea1dac",
   "metadata": {},
   "source": [
    "### 분류 - Tree 외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f4605-600f-424f-9882-fede2296e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 로지스틱 회귀: 시그모이드함수를 생성하고 입력값이 0인지 1인지 예측하여 수랭\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:,1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, pred_proba)\n",
    "print(f'accuracy: {acc:.3f}, roc_auc:{auc:.3f}')\n",
    "\n",
    "# 최적의 파라미터\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params={'solver':['liblinear', 'lbfgs'],'penalty':['l2', 'l1'],'C':[0.01, 0.1, 1, 5, 10]}\n",
    "lr_clf = LogisticRegression()\n",
    "grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring='accuracy', cv=3 )\n",
    "grid_clf.fit(cancer.data, cancer.target)\n",
    "print(f'최적 하이퍼 파라미터:{grid_clf.best_params_}') \n",
    "print(f'최대 평균 정확도:{grid_clf.best_score_:.3f}')\n",
    "\n",
    "# GridSearchCV 결과보기\n",
    "pd.DataFrame(grid_clf.cv_results_)[['mean_test_score', 'rank_test_score']] # 필요한 파라미터로\n",
    "lr_clf.coef_, lr_clf.intercept_   # 주의! 되나 봐야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5621a54-fa51-4ec6-96a4-79f5a2b52161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 최근접 이웃\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "pred_proba = knn.predict_proba(X_test)[:,1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, pred_proba)\n",
    "print(f'accuracy: {acc:.3f}, roc_auc:{auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7e5cc-b554-4fec-a5d1-298ba5812ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 서포트 벡터 머신(KVM)\n",
    "from sklearn.svm import SVC, SVR\n",
    "svc = SVC(probability = True)   # pred_proba 구할 경우 True\n",
    "svc.fit(X_train, y_train)\n",
    "pred = svc.predict(X_test)\n",
    "pred_proba = svc.predict_proba(X_test)[:,1]\n",
    "acc = accuracy_score(y_test, pred)\n",
    "auc = roc_auc_score(y_test, pred_proba)\n",
    "print(f'accuracy: {acc:.3f}, roc_auc:{auc:.3f}')\n",
    "\n",
    "# 3-1. kernel 비교하기\n",
    "kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    print(kernel)\n",
    "    svc = SVC(kernel=kernel, probability = True)\n",
    "    svc.fit(X_train, y_train)\n",
    "    pred = svc.predict(X_test)\n",
    "    pred_proba = svc.predict_proba(X_test)[:,1]\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    auc = roc_auc_score(y_test, pred_proba)\n",
    "    print(f'accuracy: {acc:.3f}, roc_auc:{auc:.3f}')\n",
    "\n",
    "# 3-2. 파라미터 찾기 GridSearchCV\n",
    "params = {'C' : [0.01, 0.1, 1, 2, 5],'gamma' : [0.01, 0.05,0.1, 0.5, 1, 2, 5]}\n",
    "grid_cv = GridSearchCV(svc, param_grid=params, scoring='accuracy', cv = 3, verbose=True)\n",
    "grid_cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6b6d0-4eaa-4d57-b486-ea88345c793d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
