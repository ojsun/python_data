# 0. 사이킷런 파일 가져오기
    from sklearn.datasets import load_iris
    iris = load_iris()

# 1. 전처리: 오류데이터 보정, null값 처리 등 데이터 클렌징작업
   인코딩: LabelEncoder, OneHotEncoder, pd.get_dummies(df)
   스케일링: StandardScaler(), MinMaxScaler()

# 2. 데이터셋트 분리
    from sklearn.model_selection import train_test_split
    iris_data = iris.data
    iris_label = iris.target
/   X_titanic=titanic_df.drop(['Survived'], axis=1)
    y_titanic=titanic_df['Survived']
/   X=diabets_data.iloc[:,:-1]
    y=diabets_data.iloc[:,-1]

# 3 df를 자르기: 종속 / 독립 변수로 나눠서 train_test_split한다.
    y_df = df['target']
    x_df = df.drop('target', axis = 1)
    X_train, X_test, y_train, y_test = 
       train_test_split(x_df, y_df, test_size = 0.2, random_state=0)

# 4. 머신러닝 : 모델(알고리즘) 선택
  - 모델학습  dt_clf = DecisionTreeClassifier(random_state = 0)
                  dt_clf.fit(X_train, y_train)
  - 예측  pred = dt_clf.predict(X_test)
	    pred_proba=lr_clf.predict_proba(X_test)
# 5.  예측 평가(방법 선택) get_clf_eval() : 쓸만한 예측평가 함수
    from sklearn.metrics import accuracy_score   
            acc = accuracy_score(y_test, pred)
	    f1_score, roc_auc_score, recall_score, precision_score
# 6. 교차검증
            cross_val_score, cross_validate, GridSearchCV

# 7. 최적의 모델 및 방법 찾기
    * 하이퍼 파라미터 : KFold, StratifiedKFold 
    * 임곗값 조절하기 get_eval_by_threshold
    * 피처 중요도 그래프 .feature_importances_
    * 트리 구조 그래프(tree 모델)
    * 과적합 확인

# 8. 학습,예측,평가 반복 또는 학습종료 후, 테스트 및 배포

