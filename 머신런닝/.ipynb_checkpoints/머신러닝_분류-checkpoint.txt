
 
1) DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier
dt_clf = DecisionTreeClassifier(random_state=156)
dt_clf.fit(X_train , y_train)
pred = dt_clf.predict(X_test)
accuracy = accuracy_score(y_test , pred)
print('결정 트리 예측 정확도: {0:.4f}'.format(accuracy))

# GridSearchCV 하이퍼 파라미터 찾기

# 피처 중요도 그래프 .feature_importances_
import matplotlib.pyplot as plt
import seaborn as sns


#트리 구조 그래프

2) ensemble 학습: Voting
from sklearn.ensemble import VotingClassifier
lr_clf = LogisticRegression(solver='liblinear')
dt_clf = DecisionTreeClassifier(random_state=0)
vo_clf = VotingClassifier( estimators=[('LR',lr_clf), ('DT',dt_clf)] , voting='soft' )


3) ensemble 학습: RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier
rf_clf = RandomForestClassifier(random_state=0)

# 랜덤포레스트 파이퍼 파라미터 튜닝 GridSearchCV
# 피쳐 중요도 그래프

4) ensemble 학습: GBM/ GradientBoostingClassifier
from sklearn.ensemble import GradientBoostingClassifier
gb_clf = GradientBoostingClassifier(random_state=0)


5) ensemble 학습: XGBoodt
import xgboost as xgb
from xgboost import plot_importance


# 그래프 그리기

6) ensemble 학습: 래퍼 XGBClassifier 
from xgboost import XGBClassifier 
xgb_wrapper = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)

7) 스태킹 앙상블


